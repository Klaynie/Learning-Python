{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Introduction to Categorical Data\n",
    "\n",
    "When exploring data, we are often interested in summarizing a large amount of information with a single number or visualization.\n",
    "\n",
    "Depending on what we are trying to understand from our data, we may need to rely on different statistics. For quantitative data, we can summarize central tendency using mean, median or mode and we can summarize spread using standard deviation, variance, or percentiles. However, when working with categorical data, we may not be able to use all the same summary statistics.\n",
    "\n",
    "For example, here are the first five rows and some selected columns of a dataset from the 1994 U.S. census:\n",
    "\n",
    "|age|education|marital.status|race|\n",
    "|:--|:--------|:-------------|:---|\n",
    "|90|HS-grad|Widowed|White|\n",
    "|82|HS-grad|Widowed|White|\n",
    "|66|Some-college|Widowed|Black|\n",
    "|54|7th-8th|Divorced|White|\n",
    "|41|Some-college|Separated|White|\n",
    "\n",
    "Age is a quantitative variable, so we can calculate the average (or mean) age. However, for a variable like `marital.status`, we can’t calculate something like \"average marital status\" because the possible values of marital status are categories rather than numbers (e.g. \"Married\", \"Widowed\", \"Seperated\", etc.). This lesson will cover summary statistics specifically for exploring categorical data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nyc_trees = pd.read_csv(\"./nyc_tree_census.csv\")"
   ]
  },
  {
   "source": [
    "1. The dataset we will explore in this lesson is a sample of the NYC 2015 Tree Census. This dataset contains information from a survey of trees in the city collected by parks department employees and community volunteers. A dataframe named nyc_trees has been loaded for you in the workspace. Take a look at the field descriptions below. Once you are ready, inspect the first five rows of nyc_trees using the .head() method and print the result.\n",
    "\n",
    "    Data Description:\n",
    "\n",
    "    |Column Name|Description|\n",
    "    |:----------|:----------|\n",
    "    |tree_id|Unique identifier for each tree in the survey|\n",
    "    |trunk_diam|Diameter of the tree measured 54” above the ground|\n",
    "    |status|Indicates whether the tree is alive, standing dead, or a stump.|\n",
    "    |health|Indicates the user’s perception of tree health.|\n",
    "    |spc_common|Common name for species, e.g. \"red maple\"|\n",
    "    |neighborhood|Name of the neighborhood the tree is located in|"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   tree_id  trunk_diam status health   spc_common  \\\n",
       "0   199250           8  Alive   Good   crab apple   \n",
       "1   136891          17  Alive   Good  honeylocust   \n",
       "2   200218           3  Alive   Good       ginkgo   \n",
       "3    53901          23  Alive   Good    green ash   \n",
       "4   589218          21  Alive   Good      pin oak   \n",
       "\n",
       "                          neighborhood  \n",
       "0                       Lincoln Square  \n",
       "1                    East Harlem North  \n",
       "2                            Chinatown  \n",
       "3                Bayside-Bayside Hills  \n",
       "4  Glen Oaks-Floral Park-New Hyde Park  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tree_id</th>\n      <th>trunk_diam</th>\n      <th>status</th>\n      <th>health</th>\n      <th>spc_common</th>\n      <th>neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>199250</td>\n      <td>8</td>\n      <td>Alive</td>\n      <td>Good</td>\n      <td>crab apple</td>\n      <td>Lincoln Square</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>136891</td>\n      <td>17</td>\n      <td>Alive</td>\n      <td>Good</td>\n      <td>honeylocust</td>\n      <td>East Harlem North</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200218</td>\n      <td>3</td>\n      <td>Alive</td>\n      <td>Good</td>\n      <td>ginkgo</td>\n      <td>Chinatown</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53901</td>\n      <td>23</td>\n      <td>Alive</td>\n      <td>Good</td>\n      <td>green ash</td>\n      <td>Bayside-Bayside Hills</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>589218</td>\n      <td>21</td>\n      <td>Alive</td>\n      <td>Good</td>\n      <td>pin oak</td>\n      <td>Glen Oaks-Floral Park-New Hyde Park</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "nyc_trees.head()"
   ]
  },
  {
   "source": [
    "2. Which of the columns are categorical variables? Write the names into a list named `categorical_vars`. Each name should be a separate string. Although id fields (for example, `tree_id`) can technically be considered categorical data, you do not need to include them in your list."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['status', 'health', 'spc_common', 'neighborhood']"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Nominal Categories\n",
    "\n",
    "Depending on the data, some of the summary statistics we use for quantitative data can still be meaningful for categorical data. Let us first consider a *nominal categorical variable*. A nominal categorical variable is a categorical variable with no intrinsic ordering to the categories. Examples from the census dataset introduced in the previous exercise include `marital.status` and `race`.\n",
    "\n",
    "Because these variables' categories have no ordering or numeric equivalents, it is impossible to calculate a mean or median. It would also be impossible to describe spread with statistics like variance, standard deviation, a range, IQR, or percentiles, because these statistics all rely on being able to order the data in some way. However, it is still possible to calculate the *mode*, the most common value in the dataset.\n",
    "\n",
    "We can do this in Python using the `.value_counts()` function. The `.value_counts()` function calculates the count of each value in a column and returns the result as a series. By default, `.value_counts()` orders categories in descending order by frequency, thus the top row in the output will be the mode.\n",
    "\n",
    "In the code below, we use `.value_counts()` to extract the most common responses in the field `marital.status`.\n",
    "\n",
    "        counts = df['marital.status'].value_counts()\n",
    "        print(counts)\n",
    "\n",
    "### Output:\n",
    "\n",
    "        Married-civ-spouse       14976\n",
    "        Never-married            10683\n",
    "        Divorced                  4443\n",
    "        Separated                 1025\n",
    "        Widowed                    993\n",
    "        Married-spouse-absent      418\n",
    "        Married-AF-spouse           23\n",
    "\n",
    "This means that the most common value of `marital.status` in this dataset is `'Married-civ-spouse'` (married to a civilian spouse), with 14976 observations in that category. We can also extract the name of the modal category by taking the first value from the series `.value_counts()` returns.\n",
    "\n",
    "        modal_cat = counts.index[0]\n",
    "        print(modal_cat) # Output: Married-civ-spouse"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise\n",
    "\n",
    "1. Using the `nyc_trees` data, find the count of trees in each neighborhood (the column name for neighborhood is `neighborhood`). Save the result as `tree_counts` and print the result.\n",
    "\n",
    "    Note that this data, like many datasets you will encounter in the real world, is large and a little messy! You will see that the neighborhoods with the fewest trees (only 1 in some cases) have some strange names that do not really seem like neighborhoods. Not to worry — this still tells you some important information!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Annadale-Huguenot-Prince's Bay-Eltingville    950\n",
       "Great Kills                                   761\n",
       "East New York                                 702\n",
       "Bayside-Bayside Hills                         665\n",
       "Rossville-Woodrow                             633\n",
       "                                             ... \n",
       "BX33                                            1\n",
       "82                                              1\n",
       "40                                              1\n",
       "86                                              1\n",
       "5                                               1\n",
       "Name: neighborhood, Length: 442, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tree_counts = nyc_trees['neighborhood'].value_counts()\n",
    "tree_counts"
   ]
  },
  {
   "source": [
    "2. Using the `nyc_trees` data, find the neighborhood with the highest tree count. Save the name of the neighborhood as a variable called `greenest_neighborhood` and print the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Annadale-Huguenot-Prince's Bay-Eltingville\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "greenest_neighborhood = tree_counts.index[0]\n",
    "greenest_neighborhood"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Ordinal Categorical Variables - Central Tendency I\n",
    "\n",
    "*Ordinal categorical variables* have ordered categories. For ordinal categorical variables, we can find the modal category just like in the previous exercise — but we can also calculate other summary statistics that are not possible for nominal categorical variables. For central tendency, this means we can also calculate a median.\n",
    "\n",
    "In order to calculate numerical statistics for ordered categories, we need to first assign numerical values to the categories. Consider the variable `education` from the census data. We can inspect the unique categories in this variable using `.unique()`:\n",
    "\n",
    "    print(list(df['education'].unique()))\n",
    "\n",
    "### Output:\n",
    "\n",
    "    ['HS-grad', 'Some-college', '7th-8th', '10th', 'Doctorate', 'Prof-school', 'Bachelors', 'Masters', '11th', 'Assoc-acdm', 'Assoc-voc', '1st-4th', '5th-6th', '12th', '9th', 'Preschool']\n",
    "\n",
    "Then, we can associate each of these categories with a numerical value, indicating an individual’s \"education level\". In Python, the easiest way to do this is to convert the variable to type `'category'` using `pandas.Categorical()`. When converting a column to type `'category'`, we can also pass a list with the column's categories (and True to the ordered parameter) to indicate the desired ordering.\n",
    "\n",
    "    correct_order = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'HS-grad', 'Some-college', 'Assoc-voc', 'Assoc-acdm', 'Bachelors', 'Masters', 'Prof-school', 'Doctorate']\n",
    " \n",
    "    df['education'] = pd.Categorical(df['education'], correct_order, ordered=True)\n",
    "\n",
    "Variables stored as type category have an attribute (`cat.codes`) that converts the categories to numbers. This allows us to perform numerical operations on this categorical field. This allows us to calculate the median category using numpy's `median()` function:\n",
    "\n",
    "    median_index = np.median(df['education'].cat.codes)\n",
    "    print(median_index) # Output: 9\n",
    " \n",
    "    median_category = correct_order[int(median_index)]\n",
    "    print(median_category) # Output: Some college\n",
    "\n",
    "By using `.cat.codes` on `education`, we are able to calculate that the median value for education level is `'9'` which translates to `'Some college'`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise\n",
    "\n",
    "1. Using the NYC trees dataset, find the unique values in the column `health`. Save the unique categories to a variable named `tree_health_statuses` and print the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Good', 'Poor', 'Fair', nan], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tree_health_statuses = nyc_trees['health'].unique()\n",
    "tree_health_statuses"
   ]
  },
  {
   "source": [
    "2. Create a list named `health_categories` which lists the categories from worst to best. You should exclude `NaN` values from your list."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_categories = ['Poor', 'Fair', 'Good']"
   ]
  },
  {
   "source": [
    "3. Using the `health_categories` list you created in the previous exercise, convert `health` in the original dataset to a categorical variable type (`'category'`)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_trees['health'] = pd.Categorical(nyc_trees['health'], health_categories, ordered=True)"
   ]
  },
  {
   "source": [
    "4. Using `cat.codes`, calculate the value that corresponds to the median value of `health`. Save it as a variable named `median_health_status` and print the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "median_index = np.median(nyc_trees['health'].cat.codes)\n",
    "median_health_status = health_categories[int(median_index)]\n",
    "median_health_status"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Ordinal Categorical Variables - Central Tendency II\n",
    "\n",
    "In the previous exercise, we used `.cat.codes` to find the median category for an ordinal categorical variable. We can use `cat.codes` to return numeric values and perform a wide range of operations on categorical data as well. However, before performing any operations, you should check to make sure they make sense in the context of the data.\n",
    "\n",
    "For example, remember that the categories for `education` (in order) are as follows:\n",
    "\n",
    "    education_levels_ordered = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th','HS-grad', 'Some-college', 'Assoc-voc', 'Assoc-acdm', 'Bachelors', 'Masters', 'Prof-school', 'Doctorate']\n",
    "\n",
    "While we can represent these categories with equally spaced numbers, there is not equal spacing between categories. Some gaps between educational attainment levels represent up to four additional years of schooling (e.g. '1st-4th' to '5th-6th'), while others represent a single additional year of schooling (e.g. from '9th' to '10th').\n",
    "\n",
    "When we use `.cat.`codes to translate these categories into integers, those integers have equal spacing. While translating categories to numbers is often necessary to store and use the order of the categories (for calculating a statistic like the median, which only relies on ordering, not spacing), we should not use those numbers to calculate statistics — such as the mean — for which the distance between values matters.\n",
    "\n",
    "In practice, researchers sometimes (albeit, incorrectly) report means for ordinal categories. For example, a researcher might want to analyze survey responses to the question \"Rate your happiness on a scale from 1 to 5 where 1 means 'very unhappy' and 5 means 'very happy'\".\n",
    "\n",
    "If that researcher calculates 'mean happiness score', they are assuming that the difference in happiness between a rating of 1 and 2 is the same as the difference in happiness for a rating of 3 and 4. In practice, this assumption is likely not true and should be acknowledged if reporting a mean of an ordinal categorical variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_trees = pd.read_csv('nyc_tree_census2.csv')\n",
    "nyc_trees['tree_diam_category'] = pd.Categorical(nyc_trees['tree_diam_category'], ['Small (0-3in)', 'Medium (3-10in)', 'Medium-Large (10-18in)', 'Large (18-24in)','Very large (>24in)'], ordered=True)"
   ]
  },
  {
   "source": [
    "1. This dataset contains two variables related to trunk size. The first variable, `trunk_diam` contains the diameter of the trunk (in inches) for each tree. The variable `tree_diam_category`, on the other hand, categorizes each tree based on the size of the trunk. The categories are: `'Small (0-3in)'`, `'Medium (3-10in)'`, `'Medium-Large (10-18in)'`, `'Large (18-24in)'`, `'Very large (>24in)'`. You will notice that these categories are not evenly spaced with respect to diameter.\n",
    "\n",
    "    Calculate the mean of `trunk_diam` (the quantitative variable), save it as `mean_diam`, and print the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11.27048"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "mean_diam = nyc_trees['trunk_diam'].mean()\n",
    "mean_diam"
   ]
  },
  {
   "source": [
    "2. We have already provided code to save `tree_diam_category` as an ordered categorical variable so that you can use `cat.codes`. Calculate the mean of `tree_diam_category`, save it in a variable named `mean_diam_cat` and print it out.\n",
    "\n",
    "    Which category does this correspond to (remember that `cat.codes` translates the categories to numbers between 0 and 4)? Note how this is different from the mean you calculated in the last checkpoint. While the mean diameter is about 11.27 inches (which would be categorized as \"Medium-Large\"), the mean category index is about 1.97, which is between `'Medium (3-10in)'` and `'Medium-Large (10-18in)'`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.97282"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "mean_diam_cat = nyc_trees['tree_diam_category'].cat.codes.mean()\n",
    "mean_diam_cat"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Ordinal Categories: Spread\n",
    "\n",
    "In the last exercise, we learned that the mean is not interpretable for ordinal categorical variables because the mean relies on the assumption of equal spacing between categories.\n",
    "\n",
    "Many other statistics we might normally use for numerical data rely on the mean. Because of this, these statistics are not appropriate for ordinal data. Remember that the standard deviation and variance both depend on the mean, without a mean, we cannot have a reliable standard deviation or variance either!\n",
    "\n",
    "Instead, we can rely on other summary statistics, like the proportion of the data within a range, or percentiles/quantiles. For example, consider the education variable from earlier. To calculate a range containing 80% of the data, we can use `np.percentile()`:\n",
    "\n",
    "    tenth_perc_ind = np.percentile(df['education'].cat.codes, 10)\n",
    "    tenth_perc_cat = correct_order[int(tenth_perc_ind)]\n",
    "    print(tenth_perc_cat) # output: 11th\n",
    "    \n",
    "    nintieth_perc_ind = np.percentile(df['education'].cat.codes, 90)\n",
    "    nintieth_perc_cat = correct_order[int(nintieth_perc_ind)]\n",
    "    print(nintieth_perc_cat): #output: Bachelors\n",
    "\n",
    "This tells us that at least 80% of respondents range in \"education level\" from 11th grade to a Bachelor's degree."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_labels_ordered = ['Small (0-3in)', 'Medium (3-10in)', 'Medium-Large (10-18in)', 'Large (18-24in)','Very large (>24in)']"
   ]
  },
  {
   "source": [
    "1. Calculate the 25th percentile for `tree_diam_category`. Use the ordered list, `size_labels_ordered`, to find the corresponding label. Save your result (the label, not the index) to a variable named `p25_tree_diam_category` and print it to the console."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Medium (3-10in)'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "p25_tree_diam_category = size_labels_ordered[int(np.percentile(nyc_trees['tree_diam_category'].cat.codes, 25))]\n",
    "p25_tree_diam_category"
   ]
  },
  {
   "source": [
    "2. Calculate the 75th percentile of `tree_diam_category`. Use the ordered list, `size_labels_ordered`, to find the corresponding label. Save your result (the label, not the index) to a variable named `p75_tree_diam_category` and print it to the console.\n",
    "\n",
    "    Together with the 25th percentile, we can use this value to determine the Interquartile Range (IQR) for `tree_diam_category`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Large (18-24in)'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "p75_tree_diam_category = size_labels_ordered[int(np.percentile(nyc_trees['tree_diam_category'].cat.codes, 75))]\n",
    "p75_tree_diam_category"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Table of Proportions\n",
    "\n",
    "You have already seen that we can use the `.value_counts()` function to get a table of frequencies for a categorical variable. A table of frequencies is often the first approach a data scientist might use to summarize a categorical variable; however, it is sometimes useful to instead look at the proportion of values in each category.\n",
    "\n",
    "For example, knowing that there are 14976 people in the census dataset who are married to a civilian spouse is hard to interpret without the context of knowing the numbers in the other categories. Instead, if we know that 32% of the surveyed population is married to a civilian spouse, we have more context about the relative frequency of this category. We can calculate proportions by dividing the frequency by the number of observations in the data.\n",
    "\n",
    "    df['education'].value_counts()/len(df['education'])\n",
    "\n",
    "We can also calculate proportions using `.value_counts()` by setting the `normalize` parameter equal to `True`:\n",
    "\n",
    "    df['education'].value_counts(normalize = True).head()\n",
    "\n",
    "Output:\n",
    "\n",
    "    HS-grad         0.322502\n",
    "    Some-college    0.223918\n",
    "    Bachelors       0.164461"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_trees = pd.read_csv(\"./nyc_tree_census.csv\")"
   ]
  },
  {
   "source": [
    "1. Calculate a table of proportions for the `status` column. Save this table of proportions as `tree_status_proportions` and print the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alive    0.9539\n",
       "Stump    0.0267\n",
       "Dead     0.0194\n",
       "Name: status, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "tree_status_proportions = nyc_trees['status'].value_counts(normalize=True)\n",
    "tree_status_proportions"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Table of Proportions: Missing Data\n",
    "\n",
    "One thing to keep in mind when calculating the proportion of data in a particular category: how are you dealing with missing data? For example, consider the `workclass` variable from the census data. This column contains 1836 missing values, coded as `NaN`. By default, those missing values are not counted by .`value_counts()`.\n",
    "\n",
    "Therefore, the results of `df['workclass'].value_counts()/len(df['workclass'])` and `df['workclass'].value_counts(normalize = True)` will be slightly different. You can set the `dropna` parameter in `.value_counts()` to determine how `NaN` values are handled in summaries of data.\n",
    "\n",
    "When we divide the frequency of each category by `len(df['workclass'])`, we are calculating the proportion of a specific workclass group as a portion of all people in the dataset. This is equivalent to setting `dropna = False` in the call to `value_counts()`.\n",
    "\n",
    "`df.workclass.value_counts(dropna = False, normalize = True)`\n",
    "\n",
    "### Output:\n",
    "\n",
    "    Private             0.697030\n",
    "    Self-emp-not-inc    0.078038\n",
    "    Local-gov           0.064279\n",
    "    NaN                 0.056386\n",
    "    State-gov           0.039864\n",
    "    Self-emp-inc        0.034274\n",
    "    Federal-gov         0.029483\n",
    "    Without-pay         0.000430\n",
    "    Never-worked        0.000215\n",
    "\n",
    "Here, we see that 5.6% of respondents have a missing (`NaN`) value of `workclass`. In contrast, using `.value_counts(normalize = True)` (or `.value_counts(normalize = True, dropna = True) to be explicit) returns proportion of a specific workclass group as a portion of people in the dataset who responded to this question.\n",
    "\n",
    "`df.workclass.value_counts(normalize = True)`\n",
    "\n",
    "### Output:\n",
    "\n",
    "    Private             0.738682\n",
    "    Self-emp-not-inc    0.082701\n",
    "    Local-gov           0.068120\n",
    "    State-gov           0.042246\n",
    "    Self-emp-inc        0.036322\n",
    "    Federal-gov         0.031245\n",
    "    Without-pay         0.000456\n",
    "    Never-worked        0.000228\n",
    "\n",
    "Note that if we do not include the missing values in our denominator, we observe slightly larger proportions in each category (and no `NaN` category) in the above output. It is important to think about how you want to deal with missing data when summarizing a categorical variable and then interpret resulting values appropriately."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise\n",
    "\n",
    "1. Using `.value_counts()`, calculate the proportions for each category in the `health` variable. The denominator for your proportions should be the number of non-missing values in the health column. Save the result to a dataframe named `health_proportions` and print the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Good    0.810986\n",
       "Fair    0.146871\n",
       "Poor    0.042143\n",
       "Name: health, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "health_proportions = nyc_trees['health'].value_counts(normalize=True)\n",
    "health_proportions"
   ]
  },
  {
   "source": [
    "2. Now, still using `.value_counts()`, add a parameter to include missing values in the denominator when calculating proportions for the `health` variable. Save the result to a dataframe named `health_proportions_2`. Why are the two sets of results different? Can you think of scenarios where one might be more appropriate to report than the other?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Good    0.7736\n",
       "Fair    0.1401\n",
       "NaN     0.0461\n",
       "Poor    0.0402\n",
       "Name: health, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "health_proportions_2 = nyc_trees['health'].value_counts(normalize=True, dropna=False)\n",
    "health_proportions_2"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Binary Categorical Variables\n",
    "\n",
    "Binary categorical variables have only two categories. In Python, these variables are often coded as `0`/`1` or `True`/`False`. This makes it easy to calculate the frequency/proportion of these variables in a dataset. For example, consider a variable `income_>50K`, which is equal to `1` if a person makes more than 50k U.S.D per year, and `0` otherwise. If we add up all the `1`s and `0`s in this column, the sum will be exactly equal to the number of `1`s (people making more than 50k):\n",
    "\n",
    "    np.sum(df['income_>50K'])  #output: 7841\n",
    "\n",
    "In Python, the same behavior holds for columns coded as `True`/`False` because `True` gets coerced to `1` and `False` gets coerced to `0` (this is also true in most other programming languages used by data scientists). Similarly, we can calculate the proportion equal to `1` or `True` by taking the mean of the column. This works because the mean is just the sum of all values in the column (which is the frequency of `1`s or `Trues`) divided by the number of values in the column:\n",
    "\n",
    "    np.mean(df['income_>50K'])  #output: 0.24\n",
    "\n",
    "Finally, we can make use of this nifty trick for any variable by using a conditional to translate a non-binary variable into `True` and `False` values. For example, recall the `workclass` variable from the previous exercise. Suppose that you want to calculate the number (or proportion) of people who work in local government. We could translate the `workclass` column to a binary variable indicating whether a person works in local government (`True`) or not (`False`) by using a conditional.\n",
    "\n",
    "    print(df.workclass == 'Local-gov')\n",
    "\n",
    "### Output:\n",
    "\n",
    "    0        False\n",
    "    1        True\n",
    "    2        True\n",
    "    3        False\n",
    "    4        False\n",
    "             ...  \n",
    "\n",
    "Then, we can use the sum or mean to calculate a frequency or proportion of `True`s in the data.\n",
    "\n",
    "    (df.workclass == 'Local-gov').sum()  #output: 2093\n",
    "    (df.workclass == 'Local-gov').mean() #output: 0.064"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. Find the frequency and proportion of trees that were recorded as `Alive`. You can do this by transforming the status variable to an indicator for if a tree is alive (indicated by `status == 'Alive'`) or not. Save the results to variables named `living_frequency` and `living_proportion` and print them to the console."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "47695\n0.9539\n"
     ]
    }
   ],
   "source": [
    "living_frequency = (nyc_trees['status'] == 'Alive').sum()\n",
    "living_proportion = (nyc_trees['status'] == 'Alive').mean()\n",
    "\n",
    "print(living_frequency)\n",
    "print(living_proportion)"
   ]
  },
  {
   "source": [
    "2. Find the frequency and proportion of trees with `trunk_diam > 30`. Save the results to variables named `giant_frequency` and `giant_proportion` and print them to the console."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1788\n0.03576\n"
     ]
    }
   ],
   "source": [
    "giant_frequency = (nyc_trees['trunk_diam'] > 30).sum()\n",
    "giant_proportion = (nyc_trees['trunk_diam'] > 30).mean()\n",
    "\n",
    "print(giant_frequency)\n",
    "print(giant_proportion)"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Review\n",
    "\n",
    "In this lesson you have learned the steps you can take to summarize and interpret summaries of nominal categorical and ordinal categorical variables.\n",
    "\n",
    "* For *nominal categorical* variables, there is no ordering to the categories. Because of this, we are limited to using the *mode* to describe central tendency and there is no way to summarize the spread.\n",
    "* For *ordinal categorical* variables, there is an implied ordering to the categories. In Python, we can use `pd.Categorical()` to transform a variable to a categorical type. The Categorical type allows us to access a numeric value for each category by using `.cat.codes`. From there, we may perform operations on this variable as if it were a regular, numeric variable.\n",
    "* However, when calculating statistics for an *ordinal categorical* variable we should be mindful that some numeric statistics rely on the assumption of **equal spacing** between categories.\n",
    "* For ordinal categorical variables, *median* and *mode* can be used to summarize the central tendency, and the IQR (or any difference between percentiles) can be used to summarize the spread.\n",
    "* Certain summary statistics (e.g. frequencies and proportions), can be used for all categorical variables. You can create true/false columns and `np.sum()` and `np.mean()` to quickly summarize what proportion of your data meets certain criteria."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Exercise\n",
    "\n",
    "As a final exercise, a new dataset has been loaded for you in the cell below. Follow the instructions below to inspect and summarize the categorical variables in this data.\n",
    "\n",
    "`film_permits` contains a sample of NYC filming permits. Inspect the first few rows. Think about how you might explore and summarize this data. Some exercises you might wish to work through:\n",
    "\n",
    "* Which variables in this data are nominal? Which are ordinal?\n",
    "* Which Boroughs are granted permits for the most TV pilot episodes?\n",
    "* Summarize the types (`Category`) and subtypes (`SubCategoryName`) of projects that get filming permits granted.\n",
    "\n",
    "Solution code is available in `solutions.py`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   EventID                      EventType           StartDateTime  \\\n",
       "0   446168                Shooting Permit  10/19/2018 02:00:00 PM   \n",
       "1   186438                Shooting Permit  10/30/2014 07:00:00 AM   \n",
       "2   445255                Shooting Permit  10/20/2018 07:00:00 AM   \n",
       "3   128794  Theater Load in and Load Outs  11/16/2013 12:01:00 AM   \n",
       "4    43547                Shooting Permit  01/10/2012 07:00:00 AM   \n",
       "\n",
       "              EndDateTime    Borough           Category  SubCategoryName  \n",
       "0  10/20/2018 02:00:00 AM  Manhattan               Film          Feature  \n",
       "1  10/31/2014 02:00:00 AM     Queens         Television  Episodic series  \n",
       "2  10/20/2018 06:00:00 PM   Brooklyn  Still Photography   Not Applicable  \n",
       "3  11/17/2013 06:00:00 AM  Manhattan            Theater          Theater  \n",
       "4  01/10/2012 07:00:00 PM   Brooklyn         Television  Episodic series  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventID</th>\n      <th>EventType</th>\n      <th>StartDateTime</th>\n      <th>EndDateTime</th>\n      <th>Borough</th>\n      <th>Category</th>\n      <th>SubCategoryName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>446168</td>\n      <td>Shooting Permit</td>\n      <td>10/19/2018 02:00:00 PM</td>\n      <td>10/20/2018 02:00:00 AM</td>\n      <td>Manhattan</td>\n      <td>Film</td>\n      <td>Feature</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186438</td>\n      <td>Shooting Permit</td>\n      <td>10/30/2014 07:00:00 AM</td>\n      <td>10/31/2014 02:00:00 AM</td>\n      <td>Queens</td>\n      <td>Television</td>\n      <td>Episodic series</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>445255</td>\n      <td>Shooting Permit</td>\n      <td>10/20/2018 07:00:00 AM</td>\n      <td>10/20/2018 06:00:00 PM</td>\n      <td>Brooklyn</td>\n      <td>Still Photography</td>\n      <td>Not Applicable</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>128794</td>\n      <td>Theater Load in and Load Outs</td>\n      <td>11/16/2013 12:01:00 AM</td>\n      <td>11/17/2013 06:00:00 AM</td>\n      <td>Manhattan</td>\n      <td>Theater</td>\n      <td>Theater</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43547</td>\n      <td>Shooting Permit</td>\n      <td>01/10/2012 07:00:00 AM</td>\n      <td>01/10/2012 07:00:00 PM</td>\n      <td>Brooklyn</td>\n      <td>Television</td>\n      <td>Episodic series</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "film_permits = pd.read_csv('film_permits.csv')\n",
    "film_permits.head()"
   ]
  },
  {
   "source": [
    "### Which variables in this data are nominal? Which are ordinal?\n",
    "\n",
    "|column|type|\n",
    "|:-----|:---|\n",
    "|EventID|int|\n",
    "|EventType|nominal|\n",
    "|StartDateTime|datetime|\n",
    "|EndDateTime|datetime|\n",
    "|Borough|nominal|\n",
    "|Category|nominal|\n",
    "|SubCategoryName|nominal|"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Which Boroughs are granted permits for the most TV pilot episodes?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Manhattan        149\n",
       "Brooklyn          89\n",
       "Queens            21\n",
       "Bronx             10\n",
       "Staten Island      2\n",
       "Name: Borough, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "film_permits[film_permits['SubCategoryName'] == 'Pilot']['Borough'].value_counts()"
   ]
  },
  {
   "source": [
    "### Summarize the types (Category) and subtypes (SubCategoryName) of projects that get filming permits granted."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Television           5271\n",
       "Film                 1765\n",
       "Theater               966\n",
       "Commercial            878\n",
       "Still Photography     658\n",
       "WEB                   313\n",
       "Student                72\n",
       "Documentary            48\n",
       "Music Video            28\n",
       "Name: Category, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "film_permits['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Episodic series            2916\n",
       "Feature                    1382\n",
       "Not Applicable             1381\n",
       "Cable-episodic             1033\n",
       "Theater                     966\n",
       "Commercial                  686\n",
       "Pilot                       271\n",
       "News                        202\n",
       "Cable-other                 126\n",
       "Reality                     124\n",
       "Morning Show                121\n",
       "Short                       120\n",
       "Promo                       112\n",
       "Made for TV/mini-series      90\n",
       "Variety                      76\n",
       "Student Film                 65\n",
       "Special/Awards Show          59\n",
       "Cable-daily                  55\n",
       "Industrial/Corporate         54\n",
       "Talk Show                    48\n",
       "PSA                          27\n",
       "Game show                    25\n",
       "Signed Artist                15\n",
       "Children                     12\n",
       "Syndication/First Run        11\n",
       "Independent Artist            9\n",
       "Magazine Show                 8\n",
       "Daytime soap                  5\n",
       "Name: SubCategoryName, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "film_permits['SubCategoryName'].value_counts()"
   ]
  }
 ]
}