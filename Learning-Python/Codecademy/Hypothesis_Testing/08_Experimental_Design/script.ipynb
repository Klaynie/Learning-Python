{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\r\n",
    "\r\n",
    "In this lesson, we will use simulation to understand some of the considerations for setting up an A/B test: sample size, power, and the false positive rate. But before we think about designing an A/B test, let us first remind ourselves how to conduct the test itself, **after** planning and collecting data.\r\n",
    "\r\n",
    "Suppose that a media company currently has a weekly newsletter email and wants to see if using the recipient's first name in the email subject will cause more people to open the email (ie. \"Bob! Checkout this week’s updates\" vs \"Checkout this week's updates\"). They randomly assign a group of 100 recipients to receive one of the two email subjects and record whether or not each recipient opened the email. The first few rows of their data might look something like this:\r\n",
    "\r\n",
    "|Email|Opened|\r\n",
    "|:----|:-----|\r\n",
    "|name|yes|\r\n",
    "|name|no|\r\n",
    "|control|yes|\r\n",
    "|control|yes|\r\n",
    "|name|no|\r\n",
    "\r\n",
    "In order to run a hypothesis test to decide whether there is a significant difference in the open rate for these emails, we would run a Chi-Square test. To accomplish this, we would first create a contingency table for the `Email` and `Opened` variables in the above table:\r\n",
    "\r\n",
    "```\r\n",
    "x = pd.crosstab(data.Email, data.Opened)\r\n",
    "print(x)\r\n",
    "```\r\n",
    "\r\n",
    "Output:\r\n",
    "\r\n",
    "|Opened|no|yes|\r\n",
    "|:-----|:-|:--|\r\n",
    "|Email|||\r\n",
    "|control|23|27|\r\n",
    "|name|16|34|\r\n",
    "\r\n",
    "We would then use this table to run a Chi-Square test and get a p-value:\r\n",
    "\r\n",
    "```\r\n",
    "chi2, pval, dof, expected = chi2_contingency(x)\r\n",
    "print(pval) #Output: 0.2186\r\n",
    "```\r\n",
    "\r\n",
    "Based on the p-value, we would make a decision about which email to use; a small p-value would provide evidence that the open rates are significantly different for the two groups, while a large p-value would suggest no significant difference."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "### Exercise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Run the code in the cell below to see the first five rows of data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "data = pd.read_csv(\"ab_data.csv\")\r\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Web_Version Purchased\n",
       "0           A        no\n",
       "1           A        no\n",
       "2           A       yes\n",
       "3           A       yes\n",
       "4           A       yes"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Web_Version</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Suppose that you are running an A/B test comparing two versions of a checkout page (version A or version B) to see whether there is a significantly different purchase rate for one version compared to the other. Data from this experiment has been loaded for you in the dataframe named `data`. Use this data to create a contingency table and save the result as `ab_contingency`, then print out the result."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "ab_contingency = pd.crosstab(data.Web_Version, data.Purchased)\r\n",
    "ab_contingency"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Purchased    no  yes\n",
       "Web_Version         \n",
       "A            24   26\n",
       "B            15   35"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Purchased</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Web_Version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Use `ab_contingency` to run a Chi-Square test using `chi2_contingency()` and save the p-value as a variable named `pval`. Print out `pval`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "_, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "pval"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.10096676200907678"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulating Data for a Chi-Square test\r\n",
    "\r\n",
    "In the last exercise, we used some data from an A/B test to run a Chi-Square test. In the next few exercises, we will build up a simulation to understand the considerations that go into choosing a sample size for that test.\r\n",
    "\r\n",
    "Again consider the A/B test example from the previous exercise, comparing email subjects with and without the recipient's first name. Suppose we know that visitors have a 50% chance of opening the control email and a 65% chance of opening the name email (30% lift!).\r\n",
    "\r\n",
    "Here we use **lift** to refer to the inherent difference in the distributions of our two groups of data. In the *A/B Testing: Sample Size Calculators* lesson, we learned that **minimum detectable effect** is the smallest size of the difference between the two groups that we want our test to be able to detect. If we set up our experiment with a minimum detectable effect of at least 20%, our statistical test should detect a difference with a \"lift\" or \"effect\" of 20% or greater. In this lesson we are going to simulate data that has a lift of 30% to demonstrate how the inherent lift impacts the power of our statistical test.\r\n",
    "\r\n",
    "We can use the aforementioned probabilities to simulate a dataset of 100 email recipients as follows:\r\n",
    "\r\n",
    "```\r\n",
    "sample_control = np.random.choice(['yes', 'no'], size=50, p=[.5, .5])\r\n",
    "sample_name = np.random.choice(['yes', 'no'], size=50, p=[.65, .35])\r\n",
    "```\r\n",
    "\r\n",
    "This gives us two simulated samples, of 50 recipients each, who hypothetically saw the name or control email subject. Each one looks something like `['yes' 'no' 'no' 'no' 'yes' 'yes' ...]`, where `'yes'` corresponds to an opened email.\r\n",
    "\r\n",
    "Next, we can assemble these arrays into a data frame that looks a lot like the one we saw in exercise 1:\r\n",
    "\r\n",
    "```\r\n",
    "group = ['control'] * 50 + ['name'] * 50\r\n",
    "outcome = list(sample_control) + list(sample_name)\r\n",
    "sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "sim_data = pd.DataFrame(sim_data)\r\n",
    "print(sim_data.head())\r\n",
    "```\r\n",
    "\r\n",
    "Output:\r\n",
    "\r\n",
    "|Email|Opened|\r\n",
    "|:----|:-----|\r\n",
    "|control|no|\r\n",
    "|control|yes|\r\n",
    "|control|yes|\r\n",
    "|control|no|\r\n",
    "|control|no|\r\n",
    "\r\n",
    "Because of how we created this data frame, all of the \"control\" observations will be listed first, followed by all of the \"name\" observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "### Exercise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. In the cell below, you see the code from the narrative, which can be used to simulate a dataset for a Chi-Square test. You will notice that we have replaced all hard-coded numbers with the following variables: `sample_size`, `control_rate`, and `name_rate` (which is calculated using `control_rate` and lift).\r\n",
    "\r\n",
    "    Press \"Run\". Inspect the output. Does it look as expected?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "sample_size = 4\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "sample_control = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "\r\n",
    "group = ['control'] * int(sample_size / 2) + ['name'] * int(sample_size / 2)\r\n",
    "outcome = list(sample_control) + list(sample_name)\r\n",
    "sim_data = {\"Button\": group, \"Opened\": outcome}\r\n",
    "sim_data = pd.DataFrame(sim_data)\r\n",
    "sim_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Button Opened\n",
       "0  control     no\n",
       "1  control     no\n",
       "2     name     no\n",
       "3     name    yes"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Button</th>\n",
       "      <th>Opened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>control</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Press \"Run\" a few more times and notice how the data changes each time even though you have not changed the code. This happens because we have provided probabilities for the outcomes; (opened or not), rather than specific values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Determining Significance\r\n",
    "\r\n",
    "Now that we have practiced simulating data for an A/B test, let us actually run a Chi-Square test for each simulated dataset and consider the decision we would make based on the outcome.\r\n",
    "\r\n",
    "If we were really running this test, we would want to use the data to make a decision about whether to use the control (old) or name (new) email subject. To make that decision, we can use a significance threshold. For example, if we’re using a significance threshold of 0.05, we will \"reject the null hypothesis\" for any p-value less than 0.05. In this context, rejecting the null would mean that we conclude that there **is** a significant difference between the open rates for the two email subjects and therefore we **should** switch to the email subject that uses the recipient’s first name.\r\n",
    "\r\n",
    "We can use the following Python statement to record whether a particular p-value is significant or not, based on a threshold of 0.05:\r\n",
    "\r\n",
    "```\r\n",
    "result = ('significant' if pval < 0.05 else 'not significant')\r\n",
    "print(result)\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "### Exercise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The code from the previous exercises is provided for you in the cell below. This code generates a simulated dataset named `sim_data` and then runs a Chi-Square test for that data, saving the p-value as pval.\r\n",
    "\r\n",
    "    An additional variable named `significance_threshold` has been defined for you, which is equal to the significance threshold for the test. After the p-value calculation, add a line of code that uses `significance_threshold` to determine whether the p-value is `'significant'` or `'not significant'`. Save the result as result and print it out."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# pre-set values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 100\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# simulate a dataset\r\n",
    "sample_control = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "\r\n",
    "group = ['control'] * int(sample_size / 2) + ['name'] * int(sample_size / 2)\r\n",
    "outcome = list(sample_control) + list(sample_name)\r\n",
    "sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "# run a chi-square test\r\n",
    "ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "chi2, pval, dof, expected = chi2_contingency(ab_contingency, correction=False)\r\n",
    "print(f\"p-Value: {pval:0.4f}\")\r\n",
    "\r\n",
    "# determine significance here:\r\n",
    "result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "print(f\"Result: {result}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p-Value: 0.1025\n",
      "Result: not significant\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Estimating Power\r\n",
    "\r\n",
    "In the last exercise, we learned how to simulate a dataset for a Chi-Square test, run the test, and then output a result: 'significant' or 'not significant'. In this exercise, we’ll repeat that process many times so that we can inspect the relative frequency of each outcome.\r\n",
    "\r\n",
    "To do this, we will start by creating an empty list to store the results of our repeated experiments. Next, we will move all of our simulation code (to create a sample dataset, run a Chi-Square test, and determine a result) inside of a for-loop. In each iteration of the loop, we will append the outcome to our results list so that we can inspect it later.\r\n",
    "\r\n",
    "The outline of the code looks something like this:\r\n",
    "\r\n",
    "```\r\n",
    "Set the sample size and subscription probabilities\r\n",
    "Create an empty list named `results`\r\n",
    "\r\n",
    "\r\n",
    "Repeat 100 times in a for-loop:\r\n",
    "   Simulate a dataset\r\n",
    "   Run a Chi-Square test\r\n",
    "   Use the p-value to determine significance\r\n",
    "   Append the result ('significant' or 'not significant') to `results`\r\n",
    "```\r\n",
    "\r\n",
    "Finally, we can inspect `results` by calculating the proportion of simulated tests where the result was `'significant'`:\r\n",
    "\r\n",
    "```\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "### Exercise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. In the cell below, we have copied over the code from the previous exercise and moved the simulation inside a for-loop as described in the narrative. We have also initialized an empty list named `results`.\r\n",
    "\r\n",
    "    Below the determination of `result`, but still inside the for-loop, add a line of code to append `result` onto `results`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 100\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control'] * int(sample_size / 2) + ['name'] * int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  chi2, pval, dof, expected = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results here:\r\n",
    "print(\"Proportion of significant results:\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Outside of the for-loop, add a line of code to print the proportion of `results` that are `'significant'`. Press \"Run\" a few times (note: you will see slightly different numbers each time because this is a random process). Approximately what proportion of the results were significant (would have led us to switch to the new, name email subject)?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 100\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control'] * int(sample_size / 2) + ['name'] * int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  _, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "propportion_of_significant_results = results.count('significant') / len(results)\r\n",
    "print(f\"Proportion of significant results: {propportion_of_significant_results:0.0%}\")\r\n",
    "\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results: 26%\n",
      "0.26\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## False Positives and True Positives\r\n",
    "\r\n",
    "In the previous exercise, we simulated 1,000 datasets and ran a Chi-Square test for each one, recording whether the results were 'significant' or 'not significant'. This allowed us to estimate the proportion of simulated datasets that led to a 'significant' result.\r\n",
    "\r\n",
    "In general, we hope that the test reflects reality. We therefore want the result to be 'significant' if there really **is** a significant difference in the probability of an open for the two email subjects (lift > 0). In that case, the proportion of significant results is the true positive rate, also called the *power* of the test. Most sample size calculators aim for a power of 80%.\r\n",
    "\r\n",
    "On the other hand, if there is no difference in the probability of an email being opened for the two email subjects (lift = 0), a 'significant' result would be a false-positive (also called a type I error). This would lead us to invest time and resources into adding first names into email subjects when there is no real pay-off in the long run."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "### Exercise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The simulation code from the previous exercises is loaded for you in the cell below. We have included the code to print out the proportion of tests where a significant result was recorded. Currently, the simulation is set up so that there is a difference in the probability of a subscription for the two buttons.\r\n",
    "\r\n",
    "    Press \"Run\" a few times and inspect the proportion of significant tests (printed to the output terminal) each time. If we ran a test with the provided sample size (100), baseline conversion rate (50%) and lift (30%), approximately what percent of the time would we correctly observe a significant result? Note that this is the \"power\" of the test."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 100\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control']*int(sample_size / 2) + ['name']*int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  _, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.29\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Now, change the value of `lift` so that the proportion of significant tests is equal to the false positive rate and press \"Run\" once more.\r\n",
    "\r\n",
    "    Note that the proportion of significant tests should be approximately equal to the significance threshold if you have done this correctly.\r\n",
    "\r\n",
    "*Hint: If the proportion of significant tests is equal to the **false positive rate**, that means the significant results are wrong and there is no difference between the groups. This means `lift` should be 0.*\r\n",
    "\r\n",
    "*Remember that lift is the inherent difference between the groups. Here, a lift of 0% will mean that we are sampling from populations that have an equal probability of a “success”.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 100\r\n",
    "lift = 0\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control']*int(sample_size / 2) + ['name']*int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  _, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.05\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trade Offs\r\n",
    "\r\n",
    "At this point, let us return to the point of view of a product manager who is actually planning this A/B test. Suppose that the product manager wants to be able to accurately detect a lift of 30% (or higher), but also wants to avoid false positives (they do not want to change the email subjects unless there is actually a difference between them). To plan their test, the product manager needs to consider the following:\r\n",
    "\r\n",
    "* Increasing the sample size increases the power of the test (the probability of detecting a difference if there **is** one); however, larger sample sizes require more time and resources.\r\n",
    "* Increasing the significance threshold also increases the power of the test; however, it simultaneously increases the false positive rate (the probability of detecting a difference when there **is not** none).\r\n",
    "\r\n",
    "Finally, if the project manager chooses a larger minimum detectable effect/lift, then they will be able to decrease the sample size without decreasing power. However, if they set up their test to detect a minimum lift of 30% (for example), they may not be able to detect smaller differences that are still meaningful."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "### Exercise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The simulation code from the previous exercises is provided for you in the cell below. Currently, the simulation is set up to use an open rate of 50% for the control email, and a lift of 30% for the name email subject. Set the sample size of 100 and press \"Run\" and make note of the proportion of significant results (which is the power of the test)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 100\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control']*int(sample_size / 2) + ['name']*int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  _, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.27\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Now increase the sample size to `500` and press \"Run\" again. Note that the power of the test also increases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 500\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control']*int(sample_size / 2) + ['name']*int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  _, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.98\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Next, increase the significance threshold to `0.10`. Note that the power of the test increases even more."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.1\r\n",
    "sample_size = 500\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control']*int(sample_size / 2) + ['name']*int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  _, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.94\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Finally, increase the lift to 40%. Note that again, the power of the test increases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.1\r\n",
    "sample_size = 500\r\n",
    "lift = 0.4\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control']*int(sample_size / 2) + ['name']*int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  _, pval, _, _ = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Review\r\n",
    "\r\n",
    "Congratulations! You have now learned how to use simulation to investigate the trade-offs for an A/B test sample-size calculation. As a recap, this lesson covered the following:\r\n",
    "\r\n",
    "* The significance threshold for a test is equal to the false positive rate\r\n",
    "* The power of a test is the probability of correctly detecting a significant result\r\n",
    "* Increasing sample size increases the power of a test\r\n",
    "* Increasing the significance threshold increases power, but also increases the false positive rate\r\n",
    "* Larger sample sizes are needed to detect smaller effect sizes\r\n",
    "\r\n",
    "Two notes about the terminology in the sample size calculator:\r\n",
    "\r\n",
    "* **Baseline conversion rate** is equivalent to our `control_rate` in the code.\r\n",
    "* **Minimum detectable effect (MDE)** is the smallest effect size (or `lift`) that we want our test to be able to detect. If the MDE is larger than our true `lift`, power will* decrease because our sample size might not be large enough to detect the difference between the two groups."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "### Exercise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 100\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control'] * int(sample_size / 2) + ['name'] * int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  chi2, pval, dof, expected = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.16\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. As a final exercise, we have provided a <a href=\"a_b_test_calculator.html\">sample size calculator</a> for an A/B test, along with the simulation code from the previous exercises. The calculator estimates the sample size needed to achieve 80% power. Plug in the following values to the sample size calculator:\r\n",
    "\r\n",
    "    * Baseline rate: 50%\r\n",
    "    * Minimum detectable effect: 30%\r\n",
    "    * Significance threshold: 5%\r\n",
    "\r\n",
    "    Then, set the sample size for the simulation code equal to the sample size indicated by the calculator. Press \"Run\" and inspect the proportion of tests that were significant. The proportion should be close to 0.80!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 330\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control'] * int(sample_size / 2) + ['name'] * int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  chi2, pval, dof, expected = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.79\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Let us now examine how MDE impacts the power of our test. Change the MDE in the calculator to 40% so that you have:\r\n",
    "\r\n",
    "    * Baseline rate: 50%\r\n",
    "    * Minimum detectable effect: 40%\r\n",
    "    * Significance threshold: 5%\r\n",
    "\r\n",
    "    Update the `sample_size` in our simulator to match the new sample size given by the calculator. Press \"Run\" and inspect the proportion of tests that were significant. Now that our MDE is *larger* than our actual effect, what do you see happens to our power?\r\n",
    "\r\n",
    "*Hint: When the Minimum Detectable Effect is larger than our actual effect, power decreases as our test does not have a large enough sample size to detect the small effect (AKA lift).*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "# preset values\r\n",
    "significance_threshold = 0.05\r\n",
    "sample_size = 180\r\n",
    "lift = 0.3\r\n",
    "control_rate = 0.5\r\n",
    "name_rate = (1 + lift) * control_rate\r\n",
    "\r\n",
    "# initialize an empty list of results\r\n",
    "results = []\r\n",
    "\r\n",
    "# start the loop\r\n",
    "for i in range(100):\r\n",
    "  # simulate data:\r\n",
    "  sample_control = np.random.choice(['yes', 'no'],  size=int(sample_size / 2), p=[control_rate, 1 - control_rate])\r\n",
    "  sample_name = np.random.choice(['yes', 'no'], size=int(sample_size / 2), p=[name_rate, 1 - name_rate])\r\n",
    "  group = ['control'] * int(sample_size / 2) + ['name'] * int(sample_size / 2)\r\n",
    "  outcome = list(sample_control) + list(sample_name)\r\n",
    "  sim_data = {\"Email\": group, \"Opened\": outcome}\r\n",
    "  sim_data = pd.DataFrame(sim_data)\r\n",
    "\r\n",
    "  # run the test\r\n",
    "  ab_contingency = pd.crosstab(np.array(sim_data.Email), np.array(sim_data.Opened))\r\n",
    "  chi2, pval, dof, expected = chi2_contingency(ab_contingency)\r\n",
    "  result = ('significant' if pval < significance_threshold else 'not significant')\r\n",
    "\r\n",
    "  # append the result to our results list:\r\n",
    "  results.append(result)\r\n",
    "\r\n",
    "# calculate proportion of significant results:\r\n",
    "print(\"Proportion of significant results:\")\r\n",
    "results =  np.array(results)\r\n",
    "print(np.sum(results == 'significant') / 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of significant results:\n",
      "0.47\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}